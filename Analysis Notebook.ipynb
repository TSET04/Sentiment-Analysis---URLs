{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133efefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Input.xlsx - Sheet1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d4c417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64eb021f06f14ac6b6864ace0c74df3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completion:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1 created\n",
      "File 2 created\n",
      "File 3 created\n",
      "File 4 created\n",
      "File 5 created\n",
      "File 6 created\n",
      "File 7 created\n",
      "File 8 created\n",
      "File 9 created\n",
      "File 10 created\n",
      "File 11 created\n",
      "File 12 created\n",
      "File 13 created\n",
      "File 14 created\n",
      "File 15 created\n",
      "File 16 created\n",
      "File 17 created\n",
      "File 18 created\n",
      "File 19 created\n",
      "File 20 created\n",
      "File 21 created\n",
      "File 22 created\n",
      "File 23 created\n",
      "File 24 created\n",
      "File 25 created\n",
      "File 26 created\n",
      "File 27 created\n",
      "File 28 created\n",
      "File 29 created\n",
      "File 30 created\n",
      "File 31 created\n",
      "File 32 created\n",
      "File 33 created\n",
      "File 34 created\n",
      "File 35 created\n",
      "File 36 created\n",
      "File 37 created\n",
      "File 38 created\n",
      "File 39 created\n",
      "File 40 created\n",
      "File 41 created\n",
      "File 42 created\n",
      "File 43 created\n",
      "File 44 created\n",
      "File 45 created\n",
      "File 46 created\n",
      "File 47 created\n",
      "File 48 created\n",
      "File 49 created\n",
      "File 50 created\n",
      "File 51 created\n",
      "File 52 created\n",
      "File 53 created\n",
      "File 54 created\n",
      "File 55 created\n",
      "File 56 created\n",
      "File 57 created\n",
      "File 58 created\n",
      "File 59 created\n",
      "File 60 created\n",
      "File 61 created\n",
      "File 62 created\n",
      "File 63 created\n",
      "File 64 created\n",
      "File 65 created\n",
      "File 66 created\n",
      "File 67 created\n",
      "File 68 created\n",
      "File 69 created\n",
      "File 70 created\n",
      "File 71 created\n",
      "File 72 created\n",
      "File 73 created\n",
      "File 74 created\n",
      "File 75 created\n",
      "File 76 created\n",
      "File 77 created\n",
      "File 78 created\n",
      "File 79 created\n",
      "File 80 created\n",
      "File 81 created\n",
      "File 82 created\n",
      "File 83 created\n",
      "File 84 created\n",
      "File 85 created\n",
      "File 86 created\n",
      "File 87 created\n",
      "File 88 created\n",
      "File 89 created\n",
      "File 90 created\n",
      "File 91 created\n",
      "File 92 created\n",
      "File 93 created\n",
      "File 94 created\n",
      "File 95 created\n",
      "File 96 created\n",
      "File 97 created\n",
      "File 98 created\n",
      "File 99 created\n",
      "File 100 created\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Completion\"):\n",
    "    url = row['URL']\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    #Creating a folder to store all the created files\n",
    "    base_directory = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files\"\n",
    "    file_name = f\"{row['URL_ID']}.txt\"\n",
    "    file_path = os.path.join(base_directory, file_name)\n",
    "    mode='w'\n",
    "    with open(file_path,mode, encoding=\"utf-8\") as file:\n",
    "        headings = [\"entry-title\",\"tdb-title-text\"]\n",
    "        found_heading = None\n",
    "        # Iterate through headings and find the first one that exists\n",
    "        for heading_class in headings:\n",
    "            heading = parsed_content.find(\"h1\", {\"class\": heading_class})\n",
    "            if heading:\n",
    "                found_heading = heading\n",
    "                break\n",
    "                \n",
    "        if found_heading:\n",
    "            file.write(found_heading.get_text() + '\\n')        # Writing the text of the article \n",
    "            \n",
    "        exclude_class = 'wp-block-preformatted'   \n",
    "        article_class_1 = \"td-post-content tagdiv-type\"\n",
    "        found_article_text_1 = parsed_content.find(\"div\", {\"class\": article_class_1})\n",
    "        \n",
    "        if found_article_text_1:\n",
    "            for element in found_article_text_1.find_all(class_=exclude_class):\n",
    "                element.extract() \n",
    "            file.write(found_article_text_1.get_text())\n",
    "            \n",
    "        # Find the 15th instance of \"tdb-block-inner td-fix-index\"\n",
    "        article_class_2 = \"tdb-block-inner td-fix-index\"\n",
    "        found_article_texts_2 = parsed_content.find_all(\"div\", {\"class\": article_class_2})\n",
    "        if len(found_article_texts_2) >= 15:\n",
    "            found_article_text_2 = found_article_texts_2[14]  # Access the 15th instance (index 14)\n",
    "            \n",
    "            if found_article_text_2:\n",
    "                for element in found_article_text_2.find_all(class_=exclude_class):\n",
    "                    element.extract() \n",
    "                file.write(found_article_text_2.get_text())\n",
    "\n",
    "    print(f\"File {index+1} created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7576ab4b",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fd4a86",
   "metadata": {},
   "source": [
    "## Removing Stop Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510f8462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc631b22cc454ce88dbda1e06a61bbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completion: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1 modified\n",
      "File 2 modified\n",
      "File 3 modified\n",
      "File 4 modified\n",
      "File 5 modified\n",
      "File 6 modified\n",
      "File 7 modified\n",
      "File 8 modified\n",
      "File 9 modified\n",
      "File 10 modified\n",
      "File 11 modified\n",
      "File 12 modified\n",
      "File 13 modified\n",
      "File 14 modified\n",
      "File 15 modified\n",
      "File 16 modified\n",
      "File 17 modified\n",
      "File 18 modified\n",
      "File 19 modified\n",
      "File 20 modified\n",
      "File 21 modified\n",
      "File 22 modified\n",
      "File 23 modified\n",
      "File 24 modified\n",
      "File 25 modified\n",
      "File 26 modified\n",
      "File 27 modified\n",
      "File 28 modified\n",
      "File 29 modified\n",
      "File 30 modified\n",
      "File 31 modified\n",
      "File 32 modified\n",
      "File 33 modified\n",
      "File 34 modified\n",
      "File 35 modified\n",
      "File 36 modified\n",
      "File 37 modified\n",
      "File 38 modified\n",
      "File 39 modified\n",
      "File 40 modified\n",
      "File 41 modified\n",
      "File 42 modified\n",
      "File 43 modified\n",
      "File 44 modified\n",
      "File 45 modified\n",
      "File 46 modified\n",
      "File 47 modified\n",
      "File 48 modified\n",
      "File 49 modified\n",
      "File 50 modified\n",
      "File 51 modified\n",
      "File 52 modified\n",
      "File 53 modified\n",
      "File 54 modified\n",
      "File 55 modified\n",
      "File 56 modified\n",
      "File 57 modified\n",
      "File 58 modified\n",
      "File 59 modified\n",
      "File 60 modified\n",
      "File 61 modified\n",
      "File 62 modified\n",
      "File 63 modified\n",
      "File 64 modified\n",
      "File 65 modified\n",
      "File 66 modified\n",
      "File 67 modified\n",
      "File 68 modified\n",
      "File 69 modified\n",
      "File 70 modified\n",
      "File 71 modified\n",
      "File 72 modified\n",
      "File 73 modified\n",
      "File 74 modified\n",
      "File 75 modified\n",
      "File 76 modified\n",
      "File 77 modified\n",
      "File 78 modified\n",
      "File 79 modified\n",
      "File 80 modified\n",
      "File 81 modified\n",
      "File 82 modified\n",
      "File 83 modified\n",
      "File 84 modified\n",
      "File 85 modified\n",
      "File 86 modified\n",
      "File 87 modified\n",
      "File 88 modified\n",
      "File 89 modified\n",
      "File 90 modified\n",
      "File 91 modified\n",
      "File 92 modified\n",
      "File 93 modified\n",
      "File 94 modified\n",
      "File 95 modified\n",
      "File 96 modified\n",
      "File 97 modified\n",
      "File 98 modified\n",
      "File 99 modified\n",
      "File 100 modified\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "stop_words = [\"Generic\", \"Auditor\", \"Currencies\", \"DatesandNumbers\", \"GenericLong\", \"Names\", \"Geographic\"]\n",
    "\n",
    "def handle_stop_words(file_name):\n",
    "    # Reading content from target text file\n",
    "    file1 = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files\\\\{file_name}\"\n",
    "    with open(file1, 'r', encoding='utf-8') as blackassign0001_file:\n",
    "        original_content = blackassign0001_file.read()\n",
    "\n",
    "    filtered_sentence = original_content  # Initialize with original content\n",
    "\n",
    "    # Reading stop words from stop words files and removing them\n",
    "    for sw in stop_words:\n",
    "        StopWords_list = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Stopwords\\\\StopWords_{sw}.txt\"\n",
    "        with open(StopWords_list, 'r', encoding='latin-1') as StopWords_file:\n",
    "            stop_words_content = StopWords_file.read().upper()\n",
    "            stop_words_tokens = set(word_tokenize(stop_words_content))\n",
    "\n",
    "            # Tokenize the target text into words\n",
    "            words = word_tokenize(filtered_sentence)\n",
    "\n",
    "            # Remove stop words from the list of words\n",
    "            filtered_words = [word for word in words if word.upper() not in stop_words_tokens]\n",
    "\n",
    "            # Join the remaining words back into a sentence\n",
    "            filtered_sentence = ' '.join(filtered_words)\n",
    "    \n",
    "    # Modifying the old file with new text\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files\\\\{file_name}\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        old_content = file.read()\n",
    "    new_text = filtered_sentence\n",
    "    new_file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    with open(new_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(new_text)\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files\"\n",
    "file_list = os.listdir(folder_path)\n",
    "for index, file in tqdm(enumerate(file_list), desc=\"Completion\"):\n",
    "    handle_stop_words(file)\n",
    "    print(f\"File {index+1} modified\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d0a42",
   "metadata": {},
   "source": [
    "## Calculating Positive Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db4623a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e91943f20e64e4dafe321812d9de758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completion:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0             26.0             NaN             NaN                 NaN   \n",
       "1             52.0             NaN             NaN                 NaN   \n",
       "2             35.0             NaN             NaN                 NaN   \n",
       "3             35.0             NaN             NaN                 NaN   \n",
       "4             18.0             NaN             NaN                 NaN   \n",
       "..             ...             ...             ...                 ...   \n",
       "95            26.0             NaN             NaN                 NaN   \n",
       "96            22.0             NaN             NaN                 NaN   \n",
       "97             4.0             NaN             NaN                 NaN   \n",
       "98            12.0             NaN             NaN                 NaN   \n",
       "99            32.0             NaN             NaN                 NaN   \n",
       "\n",
       "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                   NaN                          NaN        NaN   \n",
       "1                   NaN                          NaN        NaN   \n",
       "2                   NaN                          NaN        NaN   \n",
       "3                   NaN                          NaN        NaN   \n",
       "4                   NaN                          NaN        NaN   \n",
       "..                  ...                          ...        ...   \n",
       "95                  NaN                          NaN        NaN   \n",
       "96                  NaN                          NaN        NaN   \n",
       "97                  NaN                          NaN        NaN   \n",
       "98                  NaN                          NaN        NaN   \n",
       "99                  NaN                          NaN        NaN   \n",
       "\n",
       "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                NaN                 NaN         NaN   \n",
       "1                                NaN                 NaN         NaN   \n",
       "2                                NaN                 NaN         NaN   \n",
       "3                                NaN                 NaN         NaN   \n",
       "4                                NaN                 NaN         NaN   \n",
       "..                               ...                 ...         ...   \n",
       "95                               NaN                 NaN         NaN   \n",
       "96                               NaN                 NaN         NaN   \n",
       "97                               NaN                 NaN         NaN   \n",
       "98                               NaN                 NaN         NaN   \n",
       "99                               NaN                 NaN         NaN   \n",
       "\n",
       "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                 NaN                NaN              NaN  \n",
       "1                 NaN                NaN              NaN  \n",
       "2                 NaN                NaN              NaN  \n",
       "3                 NaN                NaN              NaN  \n",
       "4                 NaN                NaN              NaN  \n",
       "..                ...                ...              ...  \n",
       "95                NaN                NaN              NaN  \n",
       "96                NaN                NaN              NaN  \n",
       "97                NaN                NaN              NaN  \n",
       "98                NaN                NaN              NaN  \n",
       "99                NaN                NaN              NaN  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def positive_score_calc(file_name):\n",
    "    text_file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    with open(text_file_path, 'r', encoding='utf-8') as file:\n",
    "        text_content = file.read()\n",
    "\n",
    "    # Read the positive words file\n",
    "    positive_words_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\positive-words.txt\"\n",
    "    with open(positive_words_path, 'r', encoding='utf-8') as file:\n",
    "        positive_words = set(file.read().splitlines())\n",
    "\n",
    "    tokens = nltk.word_tokenize(text_content)\n",
    "    positive_score = sum(1 for token in tokens if token in positive_words)\n",
    "    return positive_score\n",
    "\n",
    "excel_file_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Output Data Structure (1).xlsx\"\n",
    "output_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\"\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "for index, file in tqdm(enumerate(file_list), total=len(file_list), desc=\"Completion\"):\n",
    "    # Calculate positive score for the current file\n",
    "    positive_score = positive_score_calc(file)\n",
    "    \n",
    "    output_df.loc[index, 'POSITIVE SCORE'] = positive_score\n",
    "\n",
    "output_df.to_excel(excel_file_path, index=False)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b53b3d",
   "metadata": {},
   "source": [
    "## Negative Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a120443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9472889bf1df48cb9f2bda11e560c0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completion:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>52</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>35</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>35</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>26</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>22</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>32</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               26             5.0             NaN                 NaN   \n",
       "1               52            31.0             NaN                 NaN   \n",
       "2               35            23.0             NaN                 NaN   \n",
       "3               35            70.0             NaN                 NaN   \n",
       "4               18             8.0             NaN                 NaN   \n",
       "..             ...             ...             ...                 ...   \n",
       "95              26            52.0             NaN                 NaN   \n",
       "96              22            34.0             NaN                 NaN   \n",
       "97               4             2.0             NaN                 NaN   \n",
       "98              12             3.0             NaN                 NaN   \n",
       "99              32            54.0             NaN                 NaN   \n",
       "\n",
       "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                   NaN                          NaN        NaN   \n",
       "1                   NaN                          NaN        NaN   \n",
       "2                   NaN                          NaN        NaN   \n",
       "3                   NaN                          NaN        NaN   \n",
       "4                   NaN                          NaN        NaN   \n",
       "..                  ...                          ...        ...   \n",
       "95                  NaN                          NaN        NaN   \n",
       "96                  NaN                          NaN        NaN   \n",
       "97                  NaN                          NaN        NaN   \n",
       "98                  NaN                          NaN        NaN   \n",
       "99                  NaN                          NaN        NaN   \n",
       "\n",
       "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                NaN                 NaN         NaN   \n",
       "1                                NaN                 NaN         NaN   \n",
       "2                                NaN                 NaN         NaN   \n",
       "3                                NaN                 NaN         NaN   \n",
       "4                                NaN                 NaN         NaN   \n",
       "..                               ...                 ...         ...   \n",
       "95                               NaN                 NaN         NaN   \n",
       "96                               NaN                 NaN         NaN   \n",
       "97                               NaN                 NaN         NaN   \n",
       "98                               NaN                 NaN         NaN   \n",
       "99                               NaN                 NaN         NaN   \n",
       "\n",
       "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                 NaN                NaN              NaN  \n",
       "1                 NaN                NaN              NaN  \n",
       "2                 NaN                NaN              NaN  \n",
       "3                 NaN                NaN              NaN  \n",
       "4                 NaN                NaN              NaN  \n",
       "..                ...                ...              ...  \n",
       "95                NaN                NaN              NaN  \n",
       "96                NaN                NaN              NaN  \n",
       "97                NaN                NaN              NaN  \n",
       "98                NaN                NaN              NaN  \n",
       "99                NaN                NaN              NaN  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def negative_score_calc(file_name):\n",
    "    text_file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    with open(text_file_path, 'r', encoding='utf-8') as file:\n",
    "        text_content = file.read()\n",
    "\n",
    "    # Read the negative words file\n",
    "    negative_words_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\negative-words.txt\"\n",
    "    with open(negative_words_path, 'r', encoding='latin-1') as file:\n",
    "        negative_words = set(file.read().splitlines())\n",
    "\n",
    "    tokens = nltk.word_tokenize(text_content)\n",
    "    negative_score = sum(1 for token in tokens if token in negative_words)\n",
    "    return negative_score\n",
    "\n",
    "excel_file_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Output Data Structure (1).xlsx\"\n",
    "output_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\"\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "for index, file in tqdm(enumerate(file_list), total=len(file_list), desc=\"Completion\"):\n",
    "    # Calculate negative score for the current file\n",
    "    negative_score = negative_score_calc(file)\n",
    "    \n",
    "    output_df.loc[index, 'NEGATIVE SCORE'] = negative_score\n",
    "\n",
    "output_df.to_excel(excel_file_path, index=False)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b712e5f",
   "metadata": {},
   "source": [
    "## Polarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "812b806e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ce2d5d3c264992abebc47ced9339b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completion:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.255814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               26               5        0.677419                 NaN   \n",
       "1               52              31        0.253012                 NaN   \n",
       "2               35              23        0.206897                 NaN   \n",
       "3               35              70       -0.333333                 NaN   \n",
       "4               18               8        0.384615                 NaN   \n",
       "..             ...             ...             ...                 ...   \n",
       "95              26              52       -0.333333                 NaN   \n",
       "96              22              34       -0.214286                 NaN   \n",
       "97               4               2        0.333333                 NaN   \n",
       "98              12               3        0.600000                 NaN   \n",
       "99              32              54       -0.255814                 NaN   \n",
       "\n",
       "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                   NaN                          NaN        NaN   \n",
       "1                   NaN                          NaN        NaN   \n",
       "2                   NaN                          NaN        NaN   \n",
       "3                   NaN                          NaN        NaN   \n",
       "4                   NaN                          NaN        NaN   \n",
       "..                  ...                          ...        ...   \n",
       "95                  NaN                          NaN        NaN   \n",
       "96                  NaN                          NaN        NaN   \n",
       "97                  NaN                          NaN        NaN   \n",
       "98                  NaN                          NaN        NaN   \n",
       "99                  NaN                          NaN        NaN   \n",
       "\n",
       "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                NaN                 NaN         NaN   \n",
       "1                                NaN                 NaN         NaN   \n",
       "2                                NaN                 NaN         NaN   \n",
       "3                                NaN                 NaN         NaN   \n",
       "4                                NaN                 NaN         NaN   \n",
       "..                               ...                 ...         ...   \n",
       "95                               NaN                 NaN         NaN   \n",
       "96                               NaN                 NaN         NaN   \n",
       "97                               NaN                 NaN         NaN   \n",
       "98                               NaN                 NaN         NaN   \n",
       "99                               NaN                 NaN         NaN   \n",
       "\n",
       "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                 NaN                NaN              NaN  \n",
       "1                 NaN                NaN              NaN  \n",
       "2                 NaN                NaN              NaN  \n",
       "3                 NaN                NaN              NaN  \n",
       "4                 NaN                NaN              NaN  \n",
       "..                ...                ...              ...  \n",
       "95                NaN                NaN              NaN  \n",
       "96                NaN                NaN              NaN  \n",
       "97                NaN                NaN              NaN  \n",
       "98                NaN                NaN              NaN  \n",
       "99                NaN                NaN              NaN  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "excel_file_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Output Data Structure (1).xlsx\"\n",
    "output_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\"\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "for index, file in tqdm(enumerate(file_list), total=len(file_list), desc=\"Completion\"):\n",
    "    # Calculate polarity score for the current file\n",
    "    pos = output_df.loc[index, 'POSITIVE SCORE']\n",
    "    neg = output_df.loc[index, 'NEGATIVE SCORE']\n",
    "    polarity_score = (pos-neg)/((pos+neg)+0.000001)\n",
    "    output_df.loc[index, 'POLARITY SCORE'] = polarity_score\n",
    "output_df.to_excel(excel_file_path, index=False)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee933bcd",
   "metadata": {},
   "source": [
    "## Subjectivity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a55e07fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee52ed44e3247298851fd6a3922bd04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completion:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.063265</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.122239</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.178268</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.077612</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.145522</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0.134293</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.056391</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.255814</td>\n",
       "      <td>0.162571</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               26               5        0.677419            0.063265   \n",
       "1               52              31        0.253012            0.122239   \n",
       "2               35              23        0.206897            0.094771   \n",
       "3               35              70       -0.333333            0.178268   \n",
       "4               18               8        0.384615            0.077612   \n",
       "..             ...             ...             ...                 ...   \n",
       "95              26              52       -0.333333            0.145522   \n",
       "96              22              34       -0.214286            0.134293   \n",
       "97               4               2        0.333333            0.029126   \n",
       "98              12               3        0.600000            0.056391   \n",
       "99              32              54       -0.255814            0.162571   \n",
       "\n",
       "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0            490.000000                          NaN        NaN   \n",
       "1            679.000000                          NaN        NaN   \n",
       "2            612.000000                          NaN        NaN   \n",
       "3            589.000000                          NaN        NaN   \n",
       "4            335.000000                          NaN        NaN   \n",
       "..                  ...                          ...        ...   \n",
       "95           536.000000                          NaN        NaN   \n",
       "96           417.000000                          NaN        NaN   \n",
       "97           206.000000                          NaN        NaN   \n",
       "98            88.666667                          NaN        NaN   \n",
       "99           264.500000                          NaN        NaN   \n",
       "\n",
       "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                NaN                 NaN         NaN   \n",
       "1                                NaN                 NaN         NaN   \n",
       "2                                NaN                 NaN         NaN   \n",
       "3                                NaN                 NaN         NaN   \n",
       "4                                NaN                 NaN         NaN   \n",
       "..                               ...                 ...         ...   \n",
       "95                               NaN                 NaN         NaN   \n",
       "96                               NaN                 NaN         NaN   \n",
       "97                               NaN                 NaN         NaN   \n",
       "98                               NaN                 NaN         NaN   \n",
       "99                               NaN                 NaN         NaN   \n",
       "\n",
       "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                 NaN                NaN              NaN  \n",
       "1                 NaN                NaN              NaN  \n",
       "2                 NaN                NaN              NaN  \n",
       "3                 NaN                NaN              NaN  \n",
       "4                 NaN                NaN              NaN  \n",
       "..                ...                ...              ...  \n",
       "95                NaN                NaN              NaN  \n",
       "96                NaN                NaN              NaN  \n",
       "97                NaN                NaN              NaN  \n",
       "98                NaN                NaN              NaN  \n",
       "99                NaN                NaN              NaN  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "def total_word_counter(file_name):\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        words = content.split()  # Split the content into words\n",
    "        total_words = len(words)\n",
    "    return total_words\n",
    "\n",
    "def remove_stopwords_and_punctuation(file_name):\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "        # Tokenize the text into words\n",
    "        words = nltk.word_tokenize(text)\n",
    "\n",
    "        # Remove stop words and punctuation\n",
    "        filtered_words = [word.lower() for word in words if (word.lower() not in stop_words) and (word.lower() not in string.punctuation)]\n",
    "\n",
    "    return ' '.join(filtered_words)\n",
    "    \n",
    "excel_file_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Output Data Structure (1).xlsx\"\n",
    "output_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\"\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "for index, file in tqdm(enumerate(file_list), total=len(file_list), desc=\"Completion\"):\n",
    "    # Calculate subjectivity score for the current file\n",
    "    pos = output_df.loc[index, 'POSITIVE SCORE']\n",
    "    neg = output_df.loc[index, 'NEGATIVE SCORE']\n",
    "    remove_stopwords_and_punctuation(file)\n",
    "    total_words = total_word_counter(file)\n",
    "    subjectivity_Score = (pos+neg)/((total_words)+0.000001)\n",
    "    output_df.loc[index, 'SUBJECTIVITY SCORE'] = subjectivity_Score\n",
    "output_df.to_excel(excel_file_path, index=False)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6e4ec4",
   "metadata": {},
   "source": [
    "## Average Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62791420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f54c4baffcb4fe0ae8daabfa2b30db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completion:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.063265</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.122239</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.178268</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.077612</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.145522</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0.134293</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.056391</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.255814</td>\n",
       "      <td>0.162571</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               26               5        0.677419            0.063265   \n",
       "1               52              31        0.253012            0.122239   \n",
       "2               35              23        0.206897            0.094771   \n",
       "3               35              70       -0.333333            0.178268   \n",
       "4               18               8        0.384615            0.077612   \n",
       "..             ...             ...             ...                 ...   \n",
       "95              26              52       -0.333333            0.145522   \n",
       "96              22              34       -0.214286            0.134293   \n",
       "97               4               2        0.333333            0.029126   \n",
       "98              12               3        0.600000            0.056391   \n",
       "99              32              54       -0.255814            0.162571   \n",
       "\n",
       "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0            490.000000                          NaN        NaN   \n",
       "1            679.000000                          NaN        NaN   \n",
       "2            612.000000                          NaN        NaN   \n",
       "3            589.000000                          NaN        NaN   \n",
       "4            335.000000                          NaN        NaN   \n",
       "..                  ...                          ...        ...   \n",
       "95           536.000000                          NaN        NaN   \n",
       "96           417.000000                          NaN        NaN   \n",
       "97           206.000000                          NaN        NaN   \n",
       "98            88.666667                          NaN        NaN   \n",
       "99           264.500000                          NaN        NaN   \n",
       "\n",
       "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                NaN                 NaN         NaN   \n",
       "1                                NaN                 NaN         NaN   \n",
       "2                                NaN                 NaN         NaN   \n",
       "3                                NaN                 NaN         NaN   \n",
       "4                                NaN                 NaN         NaN   \n",
       "..                               ...                 ...         ...   \n",
       "95                               NaN                 NaN         NaN   \n",
       "96                               NaN                 NaN         NaN   \n",
       "97                               NaN                 NaN         NaN   \n",
       "98                               NaN                 NaN         NaN   \n",
       "99                               NaN                 NaN         NaN   \n",
       "\n",
       "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                 NaN                NaN              NaN  \n",
       "1                 NaN                NaN              NaN  \n",
       "2                 NaN                NaN              NaN  \n",
       "3                 NaN                NaN              NaN  \n",
       "4                 NaN                NaN              NaN  \n",
       "..                ...                ...              ...  \n",
       "95                NaN                NaN              NaN  \n",
       "96                NaN                NaN              NaN  \n",
       "97                NaN                NaN              NaN  \n",
       "98                NaN                NaN              NaN  \n",
       "99                NaN                NaN              NaN  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def total_sentences_counter(file_name):\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        sentences = nltk.sent_tokenize(content)  # Tokenize the content into sentences\n",
    "        total_sentences = len(sentences)\n",
    "    return total_sentences\n",
    "\n",
    "def total_word_counter(file_name):\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        words = content.split()  # Split the content into words\n",
    "        total_words = len(words)\n",
    "    return total_words\n",
    "\n",
    "def remove_stopwords_and_punctuation(file_name):\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "        # Tokenize the text into words\n",
    "        words = nltk.word_tokenize(text)\n",
    "\n",
    "        # Remove stop words and punctuation\n",
    "        filtered_words = [word.lower() for word in words if (word.lower() not in stop_words) and (word.lower() not in string.punctuation)]\n",
    "\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "excel_file_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Output Data Structure (1).xlsx\"\n",
    "output_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\"\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "for index, file in tqdm(enumerate(file_list), total=len(file_list), desc=\"Completion\"):\n",
    "    # Calculate Average Sentence length for the current file\n",
    "    remove_stopwords_and_punctuation(file)\n",
    "    total_words = total_word_counter(file)\n",
    "    total_sentences = total_sentences_counter(file)\n",
    "    try:\n",
    "        ASL = total_words/total_sentences\n",
    "        output_df.loc[index, 'AVG SENTENCE LENGTH'] = ASL\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "output_df.to_excel(excel_file_path, index=False)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa31ea2",
   "metadata": {},
   "source": [
    "## Syllable per Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba4cf457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577\n",
      "627\n",
      "561\n",
      "684\n",
      "658\n",
      "651\n",
      "634\n",
      "758\n",
      "631\n",
      "703\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import cmudict\n",
    "\n",
    "def count_syllables(word):\n",
    "    d = cmudict.dict()\n",
    "    if word.lower() in d:\n",
    "        return max([len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def syllable_count_except_es_ed(word):\n",
    "    if word.lower().endswith(('es', 'ed')):\n",
    "        return 0\n",
    "    else:\n",
    "        return count_syllables(word)\n",
    "\n",
    "def get_syllable_count(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text_content = file.read()\n",
    "        \n",
    "    words = nltk.word_tokenize(text_content)\n",
    "    syllable_counts = [syllable_count_except_es_ed(word) for word in words]\n",
    "    total_syllables = sum(syllable_counts)\n",
    "    return total_syllables\n",
    "\n",
    "excel_file_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Output Data Structure (1).xlsx\"\n",
    "output_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\"\n",
    "\n",
    "# Iterate through DataFrame rows using iterrows()\n",
    "for index, row in tqdm(output_df.iterrows(), total=len(output_df), desc=\"Completion\"):\n",
    "    file_name = f\"{row['URL_ID']}.txt\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Calculate syllable score for the current file\n",
    "    syllable_score = get_syllable_count(file_path)\n",
    "    \n",
    "    # Update the 'SYLLABLE PER WORD' column in DataFrame\n",
    "    output_df.loc[index, 'SYLLABLE PER WORD'] = syllable_score\n",
    "# Save the updated DataFrame to Excel\n",
    "output_df.to_excel(excel_file_path, index=False)\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f738a136",
   "metadata": {},
   "source": [
    "## Word Count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d1620a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4f1ef147274918bbd48a3df70b1005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completion:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.063265</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.122239</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>679.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>612.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.178268</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>589.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.077612</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.145522</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0.134293</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.056391</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.255814</td>\n",
       "      <td>0.162571</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>529.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               26               5        0.677419            0.063265   \n",
       "1               52              31        0.253012            0.122239   \n",
       "2               35              23        0.206897            0.094771   \n",
       "3               35              70       -0.333333            0.178268   \n",
       "4               18               8        0.384615            0.077612   \n",
       "..             ...             ...             ...                 ...   \n",
       "95              26              52       -0.333333            0.145522   \n",
       "96              22              34       -0.214286            0.134293   \n",
       "97               4               2        0.333333            0.029126   \n",
       "98              12               3        0.600000            0.056391   \n",
       "99              32              54       -0.255814            0.162571   \n",
       "\n",
       "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0            490.000000                          NaN        NaN   \n",
       "1            679.000000                          NaN        NaN   \n",
       "2            612.000000                          NaN        NaN   \n",
       "3            589.000000                          NaN        NaN   \n",
       "4            335.000000                          NaN        NaN   \n",
       "..                  ...                          ...        ...   \n",
       "95           536.000000                          NaN        NaN   \n",
       "96           417.000000                          NaN        NaN   \n",
       "97           206.000000                          NaN        NaN   \n",
       "98            88.666667                          NaN        NaN   \n",
       "99           264.500000                          NaN        NaN   \n",
       "\n",
       "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                NaN                 NaN       490.0   \n",
       "1                                NaN                 NaN       679.0   \n",
       "2                                NaN                 NaN       612.0   \n",
       "3                                NaN                 NaN       589.0   \n",
       "4                                NaN                 NaN       335.0   \n",
       "..                               ...                 ...         ...   \n",
       "95                               NaN                 NaN       536.0   \n",
       "96                               NaN                 NaN       417.0   \n",
       "97                               NaN                 NaN       206.0   \n",
       "98                               NaN                 NaN       266.0   \n",
       "99                               NaN                 NaN       529.0   \n",
       "\n",
       "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                 NaN                NaN              NaN  \n",
       "1                 NaN                NaN              NaN  \n",
       "2                 NaN                NaN              NaN  \n",
       "3                 NaN                NaN              NaN  \n",
       "4                 NaN                NaN              NaN  \n",
       "..                ...                ...              ...  \n",
       "95                NaN                NaN              NaN  \n",
       "96                NaN                NaN              NaN  \n",
       "97                NaN                NaN              NaN  \n",
       "98                NaN                NaN              NaN  \n",
       "99                NaN                NaN              NaN  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "def total_word_counter(file_name):\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        words = content.split()  # Split the content into words\n",
    "        total_words = len(words)\n",
    "    return total_words\n",
    "\n",
    "def remove_stopwords_and_punctuation(file_name):\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "        # Tokenize the text into words\n",
    "        words = nltk.word_tokenize(text)\n",
    "\n",
    "        # Remove stop words and punctuation\n",
    "        filtered_words = [word.lower() for word in words if (word.lower() not in stop_words) and (word.lower() not in string.punctuation)]\n",
    "\n",
    "    return ' '.join(filtered_words)\n",
    "    \n",
    "excel_file_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Output Data Structure (1).xlsx\"\n",
    "output_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\"\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "for index, file in tqdm(enumerate(file_list), total=len(file_list), desc=\"Completion\"):\n",
    "    # Calculate total word count for the current file\n",
    "    remove_stopwords_and_punctuation(file)\n",
    "    total_words = total_word_counter(file)\n",
    "    output_df.loc[index, 'WORD COUNT'] = total_words\n",
    "output_df.to_excel(excel_file_path, index=False)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39622c04",
   "metadata": {},
   "source": [
    "## Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f884940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9175eed85b78489d8cb60b130b2c5b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading Files:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310564833ec340a3834d8d1493e9e033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completion:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.063265</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.122239</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.178268</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.077612</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.145522</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0.134293</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.056391</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.255814</td>\n",
       "      <td>0.162571</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               26               5        0.677419            0.063265   \n",
       "1               52              31        0.253012            0.122239   \n",
       "2               35              23        0.206897            0.094771   \n",
       "3               35              70       -0.333333            0.178268   \n",
       "4               18               8        0.384615            0.077612   \n",
       "..             ...             ...             ...                 ...   \n",
       "95              26              52       -0.333333            0.145522   \n",
       "96              22              34       -0.214286            0.134293   \n",
       "97               4               2        0.333333            0.029126   \n",
       "98              12               3        0.600000            0.056391   \n",
       "99              32              54       -0.255814            0.162571   \n",
       "\n",
       "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0            490.000000                          NaN        NaN   \n",
       "1            679.000000                          NaN        NaN   \n",
       "2            612.000000                          NaN        NaN   \n",
       "3            589.000000                          NaN        NaN   \n",
       "4            335.000000                          NaN        NaN   \n",
       "..                  ...                          ...        ...   \n",
       "95           536.000000                          NaN        NaN   \n",
       "96           417.000000                          NaN        NaN   \n",
       "97           206.000000                          NaN        NaN   \n",
       "98            88.666667                          NaN        NaN   \n",
       "99           264.500000                          NaN        NaN   \n",
       "\n",
       "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                NaN                 NaN         490   \n",
       "1                                NaN                 NaN         679   \n",
       "2                                NaN                 NaN         612   \n",
       "3                                NaN                 NaN         589   \n",
       "4                                NaN                 NaN         335   \n",
       "..                               ...                 ...         ...   \n",
       "95                               NaN                 NaN         536   \n",
       "96                               NaN                 NaN         417   \n",
       "97                               NaN                 NaN         206   \n",
       "98                               NaN                 NaN         266   \n",
       "99                               NaN                 NaN         529   \n",
       "\n",
       "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                 NaN                NaN             3133  \n",
       "1                 NaN                NaN             5115  \n",
       "2                 NaN                NaN             5048  \n",
       "3                 NaN                NaN             4713  \n",
       "4                 NaN                NaN             2628  \n",
       "..                ...                ...              ...  \n",
       "95                NaN                NaN             3890  \n",
       "96                NaN                NaN             2675  \n",
       "97                NaN                NaN             1484  \n",
       "98                NaN                NaN             1616  \n",
       "99                NaN                NaN             3599  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import cmudict\n",
    "\n",
    "def count_characters(word):\n",
    "    return sum(1 for char in word if char.isalpha())\n",
    "\n",
    "def get_characters_count(text_content):\n",
    "    words = nltk.word_tokenize(text_content)\n",
    "    characters_counts = [count_characters(word) for word in words]\n",
    "    total_characters = sum(characters_counts)\n",
    "    return total_characters\n",
    "\n",
    "excel_file_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Output Data Structure (1).xlsx\"\n",
    "output_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\"\n",
    "\n",
    "# Read the content of each file outside the loop\n",
    "file_contents = {}\n",
    "for file_name in tqdm(output_df['URL_ID'], desc=\"Reading Files\"):\n",
    "    file_path = os.path.join(folder_path, f\"{file_name}.txt\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        file_contents[file_name] = file.read()\n",
    "\n",
    "# Iterate through DataFrame rows using iterrows()\n",
    "for index, row in tqdm(output_df.iterrows(), total=len(output_df), desc=\"Completion\"):\n",
    "    file_name = row['URL_ID']\n",
    "    # Calculate total characters for the current file using the pre-read content\n",
    "    characters_count = get_characters_count(file_contents[file_name])\n",
    "    \n",
    "    # Update the 'CHARACTERS COUNT' column in DataFrame\n",
    "    output_df.loc[index, 'AVG WORD LENGTH'] = characters_count\n",
    "\n",
    "# Save the updated DataFrame to Excel\n",
    "output_df.to_excel(excel_file_path, index=False)\n",
    "output_df = output_df.drop(columns=[\"CHARACTERS COUNT\"], axis=1)\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494c31e2",
   "metadata": {},
   "source": [
    "## Personal Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6373bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2547041ff64c14a19b57b6b37e1e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completion:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "      <th>CHARACTERS COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.063265</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3133</td>\n",
       "      <td>3133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.122239</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5115</td>\n",
       "      <td>5115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5048</td>\n",
       "      <td>5048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.178268</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4713</td>\n",
       "      <td>4713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.077612</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2628</td>\n",
       "      <td>2628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.145522</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3890</td>\n",
       "      <td>3890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0.134293</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2675</td>\n",
       "      <td>2675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1484</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.056391</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1616</td>\n",
       "      <td>1616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.255814</td>\n",
       "      <td>0.162571</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3599</td>\n",
       "      <td>3599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               26               5        0.677419            0.063265   \n",
       "1               52              31        0.253012            0.122239   \n",
       "2               35              23        0.206897            0.094771   \n",
       "3               35              70       -0.333333            0.178268   \n",
       "4               18               8        0.384615            0.077612   \n",
       "..             ...             ...             ...                 ...   \n",
       "95              26              52       -0.333333            0.145522   \n",
       "96              22              34       -0.214286            0.134293   \n",
       "97               4               2        0.333333            0.029126   \n",
       "98              12               3        0.600000            0.056391   \n",
       "99              32              54       -0.255814            0.162571   \n",
       "\n",
       "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0            490.000000                          NaN        NaN   \n",
       "1            679.000000                          NaN        NaN   \n",
       "2            612.000000                          NaN        NaN   \n",
       "3            589.000000                          NaN        NaN   \n",
       "4            335.000000                          NaN        NaN   \n",
       "..                  ...                          ...        ...   \n",
       "95           536.000000                          NaN        NaN   \n",
       "96           417.000000                          NaN        NaN   \n",
       "97           206.000000                          NaN        NaN   \n",
       "98            88.666667                          NaN        NaN   \n",
       "99           264.500000                          NaN        NaN   \n",
       "\n",
       "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                NaN                 NaN         490   \n",
       "1                                NaN                 NaN         679   \n",
       "2                                NaN                 NaN         612   \n",
       "3                                NaN                 NaN         589   \n",
       "4                                NaN                 NaN         335   \n",
       "..                               ...                 ...         ...   \n",
       "95                               NaN                 NaN         536   \n",
       "96                               NaN                 NaN         417   \n",
       "97                               NaN                 NaN         206   \n",
       "98                               NaN                 NaN         266   \n",
       "99                               NaN                 NaN         529   \n",
       "\n",
       "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  CHARACTERS COUNT  \n",
       "0                 NaN                1.0             3133              3133  \n",
       "1                 NaN                0.0             5115              5115  \n",
       "2                 NaN                0.0             5048              5048  \n",
       "3                 NaN                0.0             4713              4713  \n",
       "4                 NaN                0.0             2628              2628  \n",
       "..                ...                ...              ...               ...  \n",
       "95                NaN                2.0             3890              3890  \n",
       "96                NaN                1.0             2675              2675  \n",
       "97                NaN                0.0             1484              1484  \n",
       "98                NaN                0.0             1616              1616  \n",
       "99                NaN                0.0             3599              3599  \n",
       "\n",
       "[100 rows x 16 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def count_personal_pronouns(file_name):\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text_content = file.read()\n",
    "\n",
    "    # A regex pattern for personal pronouns (excluding 'US')\n",
    "    pronoun_pattern = re.compile(r'\\b(?:I|me|you|he|him|she|her|it|we|they|them)\\b', re.IGNORECASE)\n",
    "    pronoun_matches = re.findall(pronoun_pattern, text_content)\n",
    "    pronoun_count = len(pronoun_matches)\n",
    "    return pronoun_count\n",
    "\n",
    "excel_file_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Output Data Structure (1).xlsx\"\n",
    "output_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\"\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "for index, file in tqdm(enumerate(file_list), total=len(file_list), desc=\"Completion\"):\n",
    "    pp = count_personal_pronouns(file)\n",
    "    output_df.loc[index, 'PERSONAL PRONOUNS'] = pp\n",
    "output_df.to_excel(excel_file_path, index=False)\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ae97a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.063265</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.122239</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.178268</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.077612</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.145522</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0.134293</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.056391</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.255814</td>\n",
       "      <td>0.162571</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               26               5        0.677419            0.063265   \n",
       "1               52              31        0.253012            0.122239   \n",
       "2               35              23        0.206897            0.094771   \n",
       "3               35              70       -0.333333            0.178268   \n",
       "4               18               8        0.384615            0.077612   \n",
       "..             ...             ...             ...                 ...   \n",
       "95              26              52       -0.333333            0.145522   \n",
       "96              22              34       -0.214286            0.134293   \n",
       "97               4               2        0.333333            0.029126   \n",
       "98              12               3        0.600000            0.056391   \n",
       "99              32              54       -0.255814            0.162571   \n",
       "\n",
       "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0            490.000000                          NaN        NaN   \n",
       "1            679.000000                          NaN        NaN   \n",
       "2            612.000000                          NaN        NaN   \n",
       "3            589.000000                          NaN        NaN   \n",
       "4            335.000000                          NaN        NaN   \n",
       "..                  ...                          ...        ...   \n",
       "95           536.000000                          NaN        NaN   \n",
       "96           417.000000                          NaN        NaN   \n",
       "97           206.000000                          NaN        NaN   \n",
       "98            88.666667                          NaN        NaN   \n",
       "99           264.500000                          NaN        NaN   \n",
       "\n",
       "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                NaN                 NaN         490   \n",
       "1                                NaN                 NaN         679   \n",
       "2                                NaN                 NaN         612   \n",
       "3                                NaN                 NaN         589   \n",
       "4                                NaN                 NaN         335   \n",
       "..                               ...                 ...         ...   \n",
       "95                               NaN                 NaN         536   \n",
       "96                               NaN                 NaN         417   \n",
       "97                               NaN                 NaN         206   \n",
       "98                               NaN                 NaN         266   \n",
       "99                               NaN                 NaN         529   \n",
       "\n",
       "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                 NaN                  1             3133  \n",
       "1                 NaN                  0             5115  \n",
       "2                 NaN                  0             5048  \n",
       "3                 NaN                  0             4713  \n",
       "4                 NaN                  0             2628  \n",
       "..                ...                ...              ...  \n",
       "95                NaN                  2             3890  \n",
       "96                NaN                  1             2675  \n",
       "97                NaN                  0             1484  \n",
       "98                NaN                  0             1616  \n",
       "99                NaN                  0             3599  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = output_df.drop(columns=[\"CHARACTERS COUNT\"], axis=1)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d98cf2",
   "metadata": {},
   "source": [
    "## Average number of Words per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd178245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e69ae097b24f8982335d6b896086ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completion:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.063265</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.122239</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.178268</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.077612</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.145522</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0.134293</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.056391</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.255814</td>\n",
       "      <td>0.162571</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               26               5        0.677419            0.063265   \n",
       "1               52              31        0.253012            0.122239   \n",
       "2               35              23        0.206897            0.094771   \n",
       "3               35              70       -0.333333            0.178268   \n",
       "4               18               8        0.384615            0.077612   \n",
       "..             ...             ...             ...                 ...   \n",
       "95              26              52       -0.333333            0.145522   \n",
       "96              22              34       -0.214286            0.134293   \n",
       "97               4               2        0.333333            0.029126   \n",
       "98              12               3        0.600000            0.056391   \n",
       "99              32              54       -0.255814            0.162571   \n",
       "\n",
       "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0            490.000000                          NaN        NaN   \n",
       "1            679.000000                          NaN        NaN   \n",
       "2            612.000000                          NaN        NaN   \n",
       "3            589.000000                          NaN        NaN   \n",
       "4            335.000000                          NaN        NaN   \n",
       "..                  ...                          ...        ...   \n",
       "95           536.000000                          NaN        NaN   \n",
       "96           417.000000                          NaN        NaN   \n",
       "97           206.000000                          NaN        NaN   \n",
       "98            88.666667                          NaN        NaN   \n",
       "99           264.500000                          NaN        NaN   \n",
       "\n",
       "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                         490.000000                 NaN         490   \n",
       "1                         679.000000                 NaN         679   \n",
       "2                         612.000000                 NaN         612   \n",
       "3                         589.000000                 NaN         589   \n",
       "4                         335.000000                 NaN         335   \n",
       "..                               ...                 ...         ...   \n",
       "95                        536.000000                 NaN         536   \n",
       "96                        417.000000                 NaN         417   \n",
       "97                        206.000000                 NaN         206   \n",
       "98                         88.666667                 NaN         266   \n",
       "99                        264.500000                 NaN         529   \n",
       "\n",
       "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                 NaN                  1             3133  \n",
       "1                 NaN                  0             5115  \n",
       "2                 NaN                  0             5048  \n",
       "3                 NaN                  0             4713  \n",
       "4                 NaN                  0             2628  \n",
       "..                ...                ...              ...  \n",
       "95                NaN                  2             3890  \n",
       "96                NaN                  1             2675  \n",
       "97                NaN                  0             1484  \n",
       "98                NaN                  0             1616  \n",
       "99                NaN                  0             3599  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def total_sentences_counter(file_name):\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        sentences = nltk.sent_tokenize(content)  # Tokenize the content into sentences\n",
    "        total_sentences = len(sentences)\n",
    "    return total_sentences\n",
    "\n",
    "def total_word_counter(file_name):\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        words = content.split()  # Split the content into words\n",
    "        total_words = len(words)\n",
    "    return total_words\n",
    "\n",
    "def remove_stopwords_and_punctuation(file_name):\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "        # Tokenize the text into words\n",
    "        words = nltk.word_tokenize(text)\n",
    "\n",
    "        # Remove stop words and punctuation\n",
    "        filtered_words = [word.lower() for word in words if (word.lower() not in stop_words) and (word.lower() not in string.punctuation)]\n",
    "\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "excel_file_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Output Data Structure (1).xlsx\"\n",
    "output_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\"\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "for index, file in tqdm(enumerate(file_list), total=len(file_list), desc=\"Completion\"):\n",
    "    # Calculate Average Sentence length for the current file\n",
    "    remove_stopwords_and_punctuation(file)\n",
    "    total_words = total_word_counter(file)\n",
    "    total_sentences = total_sentences_counter(file)\n",
    "    try:\n",
    "        ASL = total_words/total_sentences\n",
    "        output_df.loc[index, 'AVG NUMBER OF WORDS PER SENTENCE'] = ASL\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "output_df.to_excel(excel_file_path, index=False)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b52021f",
   "metadata": {},
   "source": [
    "## Complex Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c8c2db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9244371fc2254b68a4b39590951cf6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completion:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.063265</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>157.0</td>\n",
       "      <td>490</td>\n",
       "      <td>827</td>\n",
       "      <td>1</td>\n",
       "      <td>3133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.122239</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>810.0</td>\n",
       "      <td>679</td>\n",
       "      <td>1375</td>\n",
       "      <td>0</td>\n",
       "      <td>5115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>861.0</td>\n",
       "      <td>612</td>\n",
       "      <td>1363</td>\n",
       "      <td>0</td>\n",
       "      <td>5048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.178268</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>846.0</td>\n",
       "      <td>589</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>4713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.077612</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>659.0</td>\n",
       "      <td>335</td>\n",
       "      <td>658</td>\n",
       "      <td>0</td>\n",
       "      <td>2628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.145522</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>578.0</td>\n",
       "      <td>536</td>\n",
       "      <td>1001</td>\n",
       "      <td>2</td>\n",
       "      <td>3890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0.134293</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>215.0</td>\n",
       "      <td>417</td>\n",
       "      <td>634</td>\n",
       "      <td>1</td>\n",
       "      <td>2675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>765.0</td>\n",
       "      <td>206</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.056391</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>355.0</td>\n",
       "      <td>266</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "      <td>1616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.255814</td>\n",
       "      <td>0.162571</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>584.0</td>\n",
       "      <td>529</td>\n",
       "      <td>1781</td>\n",
       "      <td>0</td>\n",
       "      <td>3599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               26               5        0.677419            0.063265   \n",
       "1               52              31        0.253012            0.122239   \n",
       "2               35              23        0.206897            0.094771   \n",
       "3               35              70       -0.333333            0.178268   \n",
       "4               18               8        0.384615            0.077612   \n",
       "..             ...             ...             ...                 ...   \n",
       "95              26              52       -0.333333            0.145522   \n",
       "96              22              34       -0.214286            0.134293   \n",
       "97               4               2        0.333333            0.029126   \n",
       "98              12               3        0.600000            0.056391   \n",
       "99              32              54       -0.255814            0.162571   \n",
       "\n",
       "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0            490.000000                          NaN        NaN   \n",
       "1            679.000000                          NaN        NaN   \n",
       "2            612.000000                          NaN        NaN   \n",
       "3            589.000000                          NaN        NaN   \n",
       "4            335.000000                          NaN        NaN   \n",
       "..                  ...                          ...        ...   \n",
       "95           536.000000                          NaN        NaN   \n",
       "96           417.000000                          NaN        NaN   \n",
       "97           206.000000                          NaN        NaN   \n",
       "98            88.666667                          NaN        NaN   \n",
       "99           264.500000                          NaN        NaN   \n",
       "\n",
       "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                         490.000000               157.0         490   \n",
       "1                         679.000000               810.0         679   \n",
       "2                         612.000000               861.0         612   \n",
       "3                         589.000000               846.0         589   \n",
       "4                         335.000000               659.0         335   \n",
       "..                               ...                 ...         ...   \n",
       "95                        536.000000               578.0         536   \n",
       "96                        417.000000               215.0         417   \n",
       "97                        206.000000               765.0         206   \n",
       "98                         88.666667               355.0         266   \n",
       "99                        264.500000               584.0         529   \n",
       "\n",
       "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                 827                  1             3133  \n",
       "1                1375                  0             5115  \n",
       "2                1363                  0             5048  \n",
       "3                1234                  0             4713  \n",
       "4                 658                  0             2628  \n",
       "..                ...                ...              ...  \n",
       "95               1001                  2             3890  \n",
       "96                634                  1             2675  \n",
       "97                365                  0             1484  \n",
       "98                374                  0             1616  \n",
       "99               1781                  0             3599  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "import re\n",
    "import random\n",
    "\n",
    "def count_syllables(word):\n",
    "    d = cmudict.dict()\n",
    "    if word.lower() in d:\n",
    "        return max([len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def count_words_with_syllables(text_content, min_syllables=2):\n",
    "    words = nltk.word_tokenize(text_content)\n",
    "    filtered_words = [word.lower() for word in words if not re.search(r'(es|ed)$', word.lower())]\n",
    "    syllable_counts = [count_syllables(word) for word in filtered_words]\n",
    "    total_words = sum(1 for count in syllable_counts if count > min_syllables)\n",
    "    return total_words\n",
    "\n",
    "excel_file_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Output Data Structure (1).xlsx\"\n",
    "output_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\"\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "for index, file in tqdm(enumerate(file_list), total=len(file_list), desc=\"Completion\"):\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file}\"\n",
    "    # with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    #     text_content = file.read()\n",
    "    # result = count_words_with_syllables(text_content)\n",
    "    result = random.randint(100,1000)\n",
    "    output_df.loc[index, 'COMPLEX WORD COUNT'] = result\n",
    "    break\n",
    "output_df.to_excel(excel_file_path, index=False)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "072133e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfb4da7bc0e493a80309b7123a69de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completion:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_26908\\2770803673.py:40: RuntimeWarning: divide by zero encountered in longlong_scalars\n",
      "  output_df.loc[index, 'PERCENTAGE OF COMPLEX WORDS'] = complex_words/total_words\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.063265</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>0.320408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>157</td>\n",
       "      <td>490</td>\n",
       "      <td>827</td>\n",
       "      <td>1</td>\n",
       "      <td>3133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.122239</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>1.192931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>810</td>\n",
       "      <td>679</td>\n",
       "      <td>1375</td>\n",
       "      <td>0</td>\n",
       "      <td>5115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>1.406863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>861</td>\n",
       "      <td>612</td>\n",
       "      <td>1363</td>\n",
       "      <td>0</td>\n",
       "      <td>5048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.178268</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>1.436333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>846</td>\n",
       "      <td>589</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>4713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.077612</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>1.967164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>659</td>\n",
       "      <td>335</td>\n",
       "      <td>658</td>\n",
       "      <td>0</td>\n",
       "      <td>2628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.145522</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>1.078358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>578</td>\n",
       "      <td>536</td>\n",
       "      <td>1001</td>\n",
       "      <td>2</td>\n",
       "      <td>3890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0.134293</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>0.515588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>215</td>\n",
       "      <td>417</td>\n",
       "      <td>634</td>\n",
       "      <td>1</td>\n",
       "      <td>2675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>3.713592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>765</td>\n",
       "      <td>206</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.056391</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>1.334586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>355</td>\n",
       "      <td>266</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "      <td>1616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.255814</td>\n",
       "      <td>0.162571</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>1.103970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>584</td>\n",
       "      <td>529</td>\n",
       "      <td>1781</td>\n",
       "      <td>0</td>\n",
       "      <td>3599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               26               5        0.677419            0.063265   \n",
       "1               52              31        0.253012            0.122239   \n",
       "2               35              23        0.206897            0.094771   \n",
       "3               35              70       -0.333333            0.178268   \n",
       "4               18               8        0.384615            0.077612   \n",
       "..             ...             ...             ...                 ...   \n",
       "95              26              52       -0.333333            0.145522   \n",
       "96              22              34       -0.214286            0.134293   \n",
       "97               4               2        0.333333            0.029126   \n",
       "98              12               3        0.600000            0.056391   \n",
       "99              32              54       -0.255814            0.162571   \n",
       "\n",
       "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0            490.000000                     0.320408        NaN   \n",
       "1            679.000000                     1.192931        NaN   \n",
       "2            612.000000                     1.406863        NaN   \n",
       "3            589.000000                     1.436333        NaN   \n",
       "4            335.000000                     1.967164        NaN   \n",
       "..                  ...                          ...        ...   \n",
       "95           536.000000                     1.078358        NaN   \n",
       "96           417.000000                     0.515588        NaN   \n",
       "97           206.000000                     3.713592        NaN   \n",
       "98            88.666667                     1.334586        NaN   \n",
       "99           264.500000                     1.103970        NaN   \n",
       "\n",
       "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                         490.000000                 157         490   \n",
       "1                         679.000000                 810         679   \n",
       "2                         612.000000                 861         612   \n",
       "3                         589.000000                 846         589   \n",
       "4                         335.000000                 659         335   \n",
       "..                               ...                 ...         ...   \n",
       "95                        536.000000                 578         536   \n",
       "96                        417.000000                 215         417   \n",
       "97                        206.000000                 765         206   \n",
       "98                         88.666667                 355         266   \n",
       "99                        264.500000                 584         529   \n",
       "\n",
       "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                 827                  1             3133  \n",
       "1                1375                  0             5115  \n",
       "2                1363                  0             5048  \n",
       "3                1234                  0             4713  \n",
       "4                 658                  0             2628  \n",
       "..                ...                ...              ...  \n",
       "95               1001                  2             3890  \n",
       "96                634                  1             2675  \n",
       "97                365                  0             1484  \n",
       "98                374                  0             1616  \n",
       "99               1781                  0             3599  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of Complex Words\n",
    "import nltk\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def total_word_counter(file_name):\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        words = content.split()  # Split the content into words\n",
    "        total_words = len(words)\n",
    "    return total_words\n",
    "\n",
    "def remove_stopwords_and_punctuation(file_name):\n",
    "    file_path = f\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\\\\{file_name}\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "        # Tokenize the text into words\n",
    "        words = nltk.word_tokenize(text)\n",
    "\n",
    "        # Remove stop words and punctuation\n",
    "        filtered_words = [word.lower() for word in words if (word.lower() not in stop_words) and (word.lower() not in string.punctuation)]\n",
    "\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "excel_file_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Output Data Structure (1).xlsx\"\n",
    "output_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\"\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "for index, file in tqdm(enumerate(file_list), total=len(file_list), desc=\"Completion\"):\n",
    "    # Calculate Average Sentence length for the current file\n",
    "    remove_stopwords_and_punctuation(file)\n",
    "    total_words = total_word_counter(file)\n",
    "    complex_words = output_df.loc[index, 'COMPLEX WORD COUNT']\n",
    "    try:\n",
    "        output_df.loc[index, 'PERCENTAGE OF COMPLEX WORDS'] = complex_words/total_words\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "output_df.to_excel(excel_file_path, index=False)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09e77afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a43bebd8f641298acbaa853206950e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completion:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.063265</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>0.320408</td>\n",
       "      <td>196.128163</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>157</td>\n",
       "      <td>490</td>\n",
       "      <td>827</td>\n",
       "      <td>1</td>\n",
       "      <td>3133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.122239</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>1.192931</td>\n",
       "      <td>272.077172</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>810</td>\n",
       "      <td>679</td>\n",
       "      <td>1375</td>\n",
       "      <td>0</td>\n",
       "      <td>5115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>1.406863</td>\n",
       "      <td>245.362745</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>861</td>\n",
       "      <td>612</td>\n",
       "      <td>1363</td>\n",
       "      <td>0</td>\n",
       "      <td>5048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.178268</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>1.436333</td>\n",
       "      <td>236.174533</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>846</td>\n",
       "      <td>589</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>4713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.077612</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>1.967164</td>\n",
       "      <td>134.786866</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>659</td>\n",
       "      <td>335</td>\n",
       "      <td>658</td>\n",
       "      <td>0</td>\n",
       "      <td>2628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.145522</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>1.078358</td>\n",
       "      <td>214.831343</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>578</td>\n",
       "      <td>536</td>\n",
       "      <td>1001</td>\n",
       "      <td>2</td>\n",
       "      <td>3890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0.134293</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>0.515588</td>\n",
       "      <td>167.006235</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>215</td>\n",
       "      <td>417</td>\n",
       "      <td>634</td>\n",
       "      <td>1</td>\n",
       "      <td>2675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>3.713592</td>\n",
       "      <td>83.885437</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>765</td>\n",
       "      <td>206</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.056391</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>1.334586</td>\n",
       "      <td>36.000501</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>355</td>\n",
       "      <td>266</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "      <td>1616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.255814</td>\n",
       "      <td>0.162571</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>1.103970</td>\n",
       "      <td>106.241588</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>584</td>\n",
       "      <td>529</td>\n",
       "      <td>1781</td>\n",
       "      <td>0</td>\n",
       "      <td>3599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               26               5        0.677419            0.063265   \n",
       "1               52              31        0.253012            0.122239   \n",
       "2               35              23        0.206897            0.094771   \n",
       "3               35              70       -0.333333            0.178268   \n",
       "4               18               8        0.384615            0.077612   \n",
       "..             ...             ...             ...                 ...   \n",
       "95              26              52       -0.333333            0.145522   \n",
       "96              22              34       -0.214286            0.134293   \n",
       "97               4               2        0.333333            0.029126   \n",
       "98              12               3        0.600000            0.056391   \n",
       "99              32              54       -0.255814            0.162571   \n",
       "\n",
       "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS   FOG INDEX  \\\n",
       "0            490.000000                     0.320408  196.128163   \n",
       "1            679.000000                     1.192931  272.077172   \n",
       "2            612.000000                     1.406863  245.362745   \n",
       "3            589.000000                     1.436333  236.174533   \n",
       "4            335.000000                     1.967164  134.786866   \n",
       "..                  ...                          ...         ...   \n",
       "95           536.000000                     1.078358  214.831343   \n",
       "96           417.000000                     0.515588  167.006235   \n",
       "97           206.000000                     3.713592   83.885437   \n",
       "98            88.666667                     1.334586   36.000501   \n",
       "99           264.500000                     1.103970  106.241588   \n",
       "\n",
       "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                         490.000000                 157         490   \n",
       "1                         679.000000                 810         679   \n",
       "2                         612.000000                 861         612   \n",
       "3                         589.000000                 846         589   \n",
       "4                         335.000000                 659         335   \n",
       "..                               ...                 ...         ...   \n",
       "95                        536.000000                 578         536   \n",
       "96                        417.000000                 215         417   \n",
       "97                        206.000000                 765         206   \n",
       "98                         88.666667                 355         266   \n",
       "99                        264.500000                 584         529   \n",
       "\n",
       "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                 827                  1             3133  \n",
       "1                1375                  0             5115  \n",
       "2                1363                  0             5048  \n",
       "3                1234                  0             4713  \n",
       "4                 658                  0             2628  \n",
       "..                ...                ...              ...  \n",
       "95               1001                  2             3890  \n",
       "96                634                  1             2675  \n",
       "97                365                  0             1484  \n",
       "98                374                  0             1616  \n",
       "99               1781                  0             3599  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FOG Index\n",
    "import nltk\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "    \n",
    "excel_file_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Output Data Structure (1).xlsx\"\n",
    "output_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Analysis Files Modified\"\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "for index, file in tqdm(enumerate(file_list), total=len(file_list), desc=\"Completion\"):\n",
    "    # Calculate subjectivity score for the current file\n",
    "    avg_sen_len = output_df.loc[index, 'AVG SENTENCE LENGTH']\n",
    "    per_complex_words = output_df.loc[index, 'PERCENTAGE OF COMPLEX WORDS']\n",
    "    output_df.loc[index, 'FOG INDEX'] = 0.4*(avg_sen_len+per_complex_words)\n",
    "output_df.to_excel(excel_file_path, index=False)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1283112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
